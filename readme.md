# Relational Memory Accumulator (RMA)

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![.NET 8.0](https://img.shields.io/badge/.NET-8.0-purple)](https://dotnet.microsoft.com/download/dotnet/8.0)
[![Rust 1.90+](https://img.shields.io/badge/Rust-1.90+-orange)](https://www.rust-lang.org/)
[![Python 3.11-3.13](https://img.shields.io/badge/Python-3.11--3.13-blue)](https://www.python.org/downloads/)

**Un concept original de r√©seau r√©current l√©ger bas√© sur une m√©moire relationnelle explicite.**

Le **Relational Memory Accumulator (RMA)** est une architecture que j'ai con√ßue pour explorer une alternative simple et interpr√©table aux RNN/LSTM classiques, en mettant l'accent sur une **m√©moire √† court et long terme relationnelle** plut√¥t que sur des portes complexes.

Ce n'est **pas** une tentative de battre les RNN sur des t√¢ches de pr√©diction pure (o√π les RNN/LSTM excellent), mais une proposition diff√©rente : un mod√®le o√π la m√©moire est **explicite, inspectable et bas√©e sur des similarit√©s**, id√©al pour des cas o√π l'interpr√©tabilit√© et la l√©g√®ret√© comptent autant que la performance brute.

## üéØ Id√©e et Concept

L'id√©e centrale : au lieu de cacher l'information dans un √©tat r√©current opaque, on maintient :
- Une **m√©moire courte (STM)** : accumulation leaky pond√©r√©e par une relation avec le pass√©.
- Une **m√©moire longue (LTM)** : collection dynamique de vecteurs pass√©s jug√©s "importants" (via similarit√© cosinus).
- Une **relation** calcul√©e entre l'entr√©e actuelle et les souvenirs pour moduler l'accumulation.

Le mod√®le est volontairement simple, sans portes (forget, input, output comme dans LSTM), mais avec une capacit√© √† "se rappeler" des patterns similaires du pass√©.

Deux versions existent :
- **RMA** : version l√©g√®re avec sortie lin√©aire simple.
- **RMA Deep** : version enrichie d'un MLP configurable apr√®s la combinaison STM + LTM pour plus de puissance expressive.

## üìê Formules Math√©matiques

Soit \( x_t \in \mathbb{R}^d \) l'entr√©e √† l'instant \( t \).

### Relation \( R_t \)
$$
R_t = \left( \frac{1}{k} \sum_{i=1}^{k} \cos(x_t, m_i) \right) \cdot \mathbf{1}_d
$$
o√π \( m_i \) sont les \( k \) souvenirs les plus similaires dans LTM.

### M√©moire courte (STM)
$$
STM_t = \alpha \cdot STM_{t-1} + (1 - \alpha) \cdot (x_t \odot R_t)
$$

### M√©moire longue (LTM)
- Ajout si espace disponible.
- Remplacement du moins similaire si \( \cos(x_t, m_{\min}) < 0.4 \).

### √âtat combin√©
$$
combined_t = STM_t + \beta \cdot \overline{LTM}
$$

### Sortie
- **RMA** : \( y_t = W \cdot combined_t + b \)
- **RMA Deep** : \( y_t = \text{MLP}(combined_t) \) (couches fully-connected avec ReLU)

## üõ† Impl√©mentations disponibles

La biblioth√®que est impl√©ment√©e dans **3 langages** pour une accessibilit√© maximale :

| Langage | Version | Fichier principal | Notes |
|--------|---------|-------------------|-------|
| **C#** | .NET 8.0 | `src/RMA.Core/RelationalMemoryAccumulator.cs` et `RelationalMemoryAccumulatorDeep.cs` | Performante, id√©ale pour applications Windows, Unity, services |
| **Rust** | 1.70+ | `src/lib.rs` | Tr√®s rapide, m√©moire s√ªre, parfaite pour syst√®mes embarqu√©s |
| **Python** | 3.11 ‚Üí 3.13 | `src/rma/core.py` | NumPy uniquement, facile √† prototyper et tester |

Toutes les impl√©mentations suivent fid√®lement les m√™mes formules.

## üöÄ Domaines d'utilisation recommand√©s

Le RMA n'est **pas** con√ßu pour battre les RNN/LSTM sur des benchmarks classiques (pr√©diction de sinuso√Øde, langage, etc.), mais il brille particuli√®rement dans :

- **Maintenance pr√©dictive** (serveurs, machines) : d√©tection de pannes √† partir de m√©triques irr√©guli√®res gr√¢ce √† la m√©moire relationnelle.
- **Robotique embarqu√©e** : correction d'√©quilibre ou navigation avec ressources limit√©es.
- **D√©tection d'anomalies rares** : capacit√© √† relier un √©v√©nement actuel √† un pattern similaire vu il y a longtemps.
- **Syst√®mes interpr√©tables** : la LTM est inspectable (on peut voir quels vecteurs sont m√©moris√©s).
- **Edge AI** : tr√®s l√©ger, peu de param√®tres, pas besoin de GPU.

Sur une t√¢che de pr√©diction de s√©rie temporelle classique, le RMA Deep atteint un MSE comp√©titif (~0.02‚Äì0.04), mais reste derri√®re un RNN optimis√© ‚Äî ce qui est normal et attendu.

## üìä √âvaluation

Un programme de comparaison est fourni (`RMA.Evaluation` en C#) qui teste :
- RNN simple (50 unit√©s cach√©es)
- RMA Original
- RMA Deep (128-64-32)

R√©sultats typiques sur pr√©diction de sinuso√Øde bruit√©e :
- RNN : ~0.013
- RMA Original : ~0.39
- RMA Deep : ~0.03‚Äì0.04 (avec entra√Ænement adapt√©)

Le RMA Deep est comp√©titif, mais le vrai avantage r√©side dans son interpr√©tabilit√© et sa l√©g√®ret√©.

## ‚öôÔ∏è Utilisation rapide

### C#
```csharp
var rma = new RelationalMemoryAccumulatorDeep(1, new int[] {64, 32}, 1);
double[] output = rma.Step(new double[] { value });
```

### Rust
```rust
let mut rma = RelationalMemoryAccumulatorDeep::new(1, vec![64, 32], 1, 0.95, 0.6, 8, 200);
let output = rma.step(&vec![value]);
```

### Python
```python
from rma.core import RelationalMemoryAccumulatorDeep
rma = RelationalMemoryAccumulatorDeep(1, [64, 32], 1)
output = rma.step([value])
```

## üìù Licence

[MIT License](LICENSE) ‚Äî libre pour usage personnel, commercial, modification.

Vous pouvez utiliser, modifier, distribuer le code librement, tant que la notice de copyright est conserv√©e.

## ‚ú® Conclusion

Le RMA n'est pas une r√©volution en performance brute, mais une **exploration int√©ressante** d'une m√©moire r√©currente explicite et relationnelle. Il montre qu'on peut obtenir des r√©sultats d√©cents avec une architecture tr√®s simple, interpr√©table et multi-langages.

Id√©al pour les projets o√π la compr√©hension du mod√®le compte autant que ses pr√©dictions.

**Contributions bienvenues** : benchmarks, nouveaux cas d'usage, optimisations !

